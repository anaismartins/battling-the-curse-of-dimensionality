---
title: "Partial Least Squares"
author: "Ana Martins"
date: "2022-11-16"
output: html_document
---

```{r}
library(tidyverse)
library(pls)
library(glmnet)

set.seed(45)
```


**1. Download the corn data and store it in your assignment folder.**

```{r}
corn <- read_rds("data/corn.rds")
```

**2. Pick a property (Moisture, Oil, Starch, or Protein) to predict.**

```{r}
corn %>%
  ggplot() +
  geom_histogram(aes(x = Moisture),
                 color = "#1b9e77",
                 alpha = 0.2,
                 fill = "#1b9e77") +
  geom_label(aes(x = 13, y = 40),
             label = "Moisture",
             color = "#1b9e77",
             fill = "white") +
  geom_histogram(aes(x = Oil),
                 color = "#d95f02",
                 alpha = 0.2,
                 fill = "#d95f02") +
  geom_label(aes(x = 13, y = 35),
             label = "Oil",
             color = "#d95f02",
             fill = "white") +
  geom_histogram(aes(x = Protein),
                 color = "#7570b3",
                 alpha = 0.2,
                 fill = "#7570b3") +
  geom_label(aes(x = 13, y = 30),
             label = "Protein",
             color = "#7570b3",
             fill = "white") +
  theme_minimal()
```

Protein seems to have the largest variance so it can be beneficial to try to predict it as opposed to the others.

**3. Split your data into a training (80%) and test (20%) set.**

```{r}
split <- c(rep(1, length.out = 80*0.8), rep(0, length.out = 80*0.2))

corn <-
  corn %>% 
  mutate(split = sample(split)) %>% 
  select(-Moisture, -Oil, -Starch)

corn_train <-
  corn %>% 
  filter(split == 1) %>% 
  select(-split)

corn_test <-
  corn %>% 
  filter(split == 0) %>% 
  select(-split)
```

**4. Use the function plsr from the package pls to estimate a partial least squares model, predicting the property using the NIR spectroscopy measurements in the training data.** Make sure that the features are on the same scale. Use leave-one-out cross-validation (built into plsr) to estimate out-of-sample performance.

```{r}
plsr_mod <- plsr(Protein ~ ., data = corn_train, scale = TRUE, validation = "LOO")

RMSEP(plsr_mod)
plot(RMSEP(plsr_mod), legendpos = "topright")
```

**5. Find out which component best predicts the property you chose. Explain how you did this.**

```{r}
# first we get the coefficients from the model, which is the weight that is given to each variable
coefficients = coef(plsr_mod)
# then we sort them
coefficients_ordered = sort(abs(coefficients[,,]))
# and then we can plot them in a barplot to see their relative importances
barplot(tail(coefficients_ordered, 5))
```

And we find that the component that best predicts the Protein is `2436`.

**6. Create a plot with on the x-axis the wavelength, and on the y-axis the strength of the loading for this component. Explain which wavelengths are most important for predicting the property you are interested in.**

```{r}
wavelengths <- as.numeric(tail(names(corn_test), 700))

wv.coefs <- tibble(wavelengths, coefficients)

wv.coefs %>%
  ggplot() +
  geom_histogram(aes(x = wavelengths, y = abs(coefficients)), stat = "identity", color = "#1b9e77") +
  theme_minimal()
```

The higher wavelengths seem more important for the prediction, since their coefficients are higher.

**7. Pick the number of components included in the model based on the “one standard deviation” rule (selectNcomp()). Create predictions for the test set using the resulting model.**

```{r}
ncomp <- selectNcomp(plsr_mod, method = "onesigma")

plsr_pred <- predict(plsr_mod, newdata = corn_test, ncomp = ncomp)
```

**8. Compare your PLS predictions to a LASSO linear regression model where lambda is selected based on cross-validation with the one standard deviation rule (using cv.glmnet).**

```{r}
train_predictors <-
  corn_train %>%
  select(-Protein)
train_predictors <- as.matrix(train_predictors)

lasso_mod <- cv.glmnet(train_predictors, corn_train$Protein)

test_predictors <-
  corn_test %>%
  select(-Protein)
test_predictors <- as.matrix(test_predictors)

lasso_pred <- predict(lasso_mod, newx = test_predictors, s = "lambda.1se")

mse <- function(true, pred){
  mean((true - pred)*(true - pred))
}

mse(corn_test$Protein, plsr_pred)
mse(corn_test$Protein, lasso_pred)
```

The Partial Least Squares method has better predictions, since it has lower MSE.