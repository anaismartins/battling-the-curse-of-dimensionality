---
title: "Practical 1"
author: "Ana Martins"
date: "2022-11-15"
output: html_document
---

```{r}
library(tidyverse)
library(glmnet)
set.seed(45)
```

## Gene expression data

**1. Read the data file gene_expressions.rds using read_rds(). What are the dimensions of the data? What is the sample size?**

```{r}
gene_expressions <- read_rds("data/gene_expressions.rds")
```

The sample has 237 observations with 54676 features.

**2. As always, visualisation is a good idea. Create histograms of the first 6 variables. Describe what you notice.**

```{r}
gene_expressions %>% 
  ggplot() +
  geom_histogram(aes(x = `1007_s_at`), fill = NA, color = "red") +
  geom_label(aes(x = 10.5, y = 80, label = "1007_s_at"), color = "red") +
  geom_histogram(aes(x = `1053_at`), fill = NA, color = "orange") +
  geom_label(aes(x = 7.5, y = 70, label = "1053_at"), color = "orange") +
  geom_histogram(aes(`117_at`), fill = NA, color = "yellow") +
  geom_label(aes(x = 6, y = 50, label = "117_at"), color = "yellow") +
  geom_histogram(aes(`121_at`), fill = NA, color = "green") +
  geom_label(aes(x = 6.5, y = 80, label = "121_at"), color = "green") +
  geom_histogram(aes(`1255_g_at`), fill = NA, color = "blue") +
  geom_label(aes(x = 3, y = 130, label = "1255_g_at"), color = "blue") +
  geom_histogram(aes(`1294_at`), fill = NA, color = "purple") +
  geom_label(aes(x = 8.5, y = 60, label = "1294_at"), color = "purple") +
  theme_minimal()
```

They all have a peak at different heights.

**3. We now only have the gene expression data, but the labels are in the file phenotypes.rds. Load that file, select() the relevant columns for classification into normal and tumor tissue, and join() it with the gene expression data, based on the tissue identifier in the sample column. Give the resulting dataset a good name!**

```{r}
phenotypes <- read_rds("data/phenotypes.rds") 

phenotypes <-
  phenotypes %>% 
  select(sample, disease)

data <- left_join(gene_expressions, phenotypes)
```

**4. Does this dataset suffer from class imbalance?**

```{r}
data <-
  data %>% 
  mutate(disease = as.factor(disease))
summary(data["disease"])
```

No, the the classes are pretty evenly distributed.

**5. Split the data into a training (80%) and a test set (20%). We will use the training set for model development in the next section.**

```{r}
split <- c(rep(1, length.out = 237*0.8 + 1), rep(0, length.out = 237*0.2))

data <-
  data %>% 
  mutate(split = sample(split))

train <-
  data %>% 
  filter(split == 1) %>% 
  select(-split)

test <-
  data %>% 
  filter(split == 0) %>% 
  select(-split)
```

## Correlation filter & logistic regression

**6. Use a correlation filter to find the IDs of the 10 genes that are most related to disease status.**

```{r}
predictors <- as.matrix(train[, 2:999])

correlation <- sort(abs(cor(predictors, as.numeric(train$disease))[,]))
(most_correlated <- names(tail(correlation, 10)))
```

**7. Perform logistic regression, predicting the outcome using the selected genes. Name the fitted object fit_lr.**

```{r}
filtered_train <-
  train %>% 
  select(disease, names(most_correlated))

filtered_test <-
  test %>% 
  select(disease, names(most_correlated))

fit_lr <- glm(formula = disease ~ ., data = filtered_train, family = binomial)
pred_lr <-
  predict(fit_lr, type = "response")

filtered_train <-
  filtered_train %>% 
  mutate(pred_lr = ifelse(pred_lr < 0.5, 0, 1))
```

**8. Create a confusion matrix for the predictions of this model on the test set. What is the accuracy of this model?**

```{r}
pred_lr_test <- predict(fit_lr, newdata = filtered_test, type = "response")

filtered_test <-
  filtered_test %>% 
  mutate(pred_lr = ifelse(pred_lr_test < 0.5, 0, 1))

table(true = filtered_test$disease, pred = filtered_test$pred_lr)
```

The accuracy is 83%.

## Regularized regression

**9. Prepare your data for input into glmnet. Create x_train, y_train, x_test, and y_test.**

```{r}
x_train <- as.matrix(train[, 2:999])
y_train <- train$disease
x_test <- as.matrix(test[,2:999])
y_test <- test$disease
```

**10. Use the glmnet function to fit a LASSO regression. Use the plot() function on the fitted model and describe what you see.**

```{r}
fit_lasso <- glmnet(x_train, y_train, family = binomial)
plot(fit_lasso)
```

Only some coefficients are actually very different from zero when we go to a high L1 norm, meaning only some variables will actually be relevant.

**11. Run cv.glmnet for your dataset. Run the plot() function on the resulting object. Explain in your own words what you see.** NB: Do not forget to set family = "binomial" to ensure that you are running logistic regression.

```{r}
fit_cv_lasso <- cv.glmnet(x_train, y_train, family = binomial)
plot(fit_cv_lasso)
```

The higher the log(lambda) the higher the GLM Deviance.

**12. Inspect the nonzero coefficients of the model with the lowest out-of-sample deviance. Hint: use the coef() function, and make sure to use the right value for the s argument to that function. Do you see overlap between the correlation filter selections and the LASSO results?**

```{r}
coefs_lasso <- rownames(coef(fit_cv_lasso, s = 'lambda.min'))[coef(fit_cv_lasso, s = 'lambda.min')[,1]!= 0]

sum = 0
for (i in most_correlated){
  sum = sum + ifelse(i %in% coefs_lasso, 1, 0)
}

sum
```

Meaning there is almost a 50% overlap.

**13. Use the predict() function on the fitted cv.glmnet object to predict disease status for the test set based on the optimized lambda value. Create a confusion matrix and compare this with the logistic regression model we made earlier in terms of accuracy.**

```{r}
pred_cv_lasso_test <- predict(fit_cv_lasso, s = "lambda.min", type = "response", newx = x_test)

test <-
  test %>% 
  mutate(pred_cv_lasso_test = ifelse(pred_cv_lasso_test < 0.5, 0, 1))

table(true = test$disease, pred = test$pred_cv_lasso_test)
```

The accuracy is the same (and so is the table).