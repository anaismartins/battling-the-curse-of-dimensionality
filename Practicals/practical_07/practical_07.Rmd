---
title: 'Practical 7: Time Series'
author: "Ana Martins"
date: "2023-01-11"
output: html_document
---

## 1 Introduction

```{r}
library(expsmooth)
library(fpp3)
library(fable.prophet)
library(patchwork)
```

## 2 Take-home exercises

### Data exploration

**1. Look at the data ukcars, and describe the structure of this data file. What type of object is ukcars?**

```{r}
ukcars
typeof(ukcars)
```

In this data file we have the car production in each quarter of the year from 1977 to 2005. R outputs the data type as double, which is the type of the number of cars produced, which is the non-index value.

Rows are years, columns are quarters (seasons). This is a time series object: For these objects the correct time order of the data points (including the different quarters in the columns) is included in the object.

*2. Before anything else, we will convert this object to a “time series tibble” or tsibble object called ts_cars. Use the function as_tsibble() for this. Describe what is different about ts_cars relative to ukcars.**

```{r}
ts_cars <- as_tsibble(ukcars)
ts_cars
typeof(ts_cars)
```

Now we have the car production values all in one column and we have the quarters indexed.

ts_cars now has only 2 columns, an index and a value. This format is more amenable to multivariate time series, for example. ts_Cars also has identified nicely that this is quarterly data!
The function `as_tsibble` can be used directly on time series objects such as `ukcars` to create a valid tsibble. For other types of objects you may need to specify more options to create a tsibble (or you can try making it into a time series with ts() first).

*3. First, create a line plot of the data. You can do this yourself (by mapping aesthetics and specifying geoms) or you can use the function autoplot() for this. Are there any patterns visible in these data?**

```{r}
autoplot(ts_cars)
```

There is first a downwards and then an upwards trend. There also seems to be some seasonality but you cannot quite find the rule.

There are clear trends over time: there is a decrease at the beginning, followed by an increase, then a sudden dip, followed by a partial recovery. At a shorter timescale, there also seems a seasonal pattern (i.e., an annual period). These data are not stationary.

*4. Create a line plot for the period between 1980 and 2000. This can be done by first filtering the data based on year(index) and then passing the result to the autoplot() function.**

```{r}
ts_cars %>% 
  filter(index > yearquarter("1980 Q1"), index < yearquarter("2000 Q1")) %>% 
  autoplot()
```


**5. A second useful way to visualize the data is by plotting the autocorrelation function. You can use the function ACF() to compute the autocorrelation function and then use autoplot() on this object to plot the ACF. Are there specific features to notice about the ACF of these data?**

```{r}
ACF(ts_cars) %>% 
  autoplot()
```

For every data point, the correlation goes over the threshold, meaning there is high correlation in this data.

The autocorrelations are quite high and stay like that for a long time (i.e., over larger lags as well). This matches the fact that there are long-term trends visible in the data (see sequence plot we made above). Furthermore, there is a peak at lags 4, 8, 12, etc., which is consistent with the idea that these data contain a seasonal effect.

## 3 Lab exercises

### 3.1 Decomposition

**6. Create an STL decomposition for the whole ts_cars data (trend, season, remainder) using a window size of 15 for the trend. Then, extract the components using the components() function and show the first few rows of the resulting tsibble.**

Hint: look at the example in the help file of the STL function to see how to estimate models using the fable workflow.

```{r}
plot(stl_cars <- stl(ts_cars, s.window = "periodic", t.window = 15))
head(ts_stl_cars <- stl_cars$time.series)
```

```{r}
stl_decomp <-
  ts_cars %>% 
  model(STL(value ~ trend(window = 15))) %>% 
  components()

head(stl_decomp)
```


**7. Use the autoplot function to plot the individual components.**

```{r}
ts_stl_cars %>% autoplot()
```

```{r}
autoplot(stl_decomp)
```


**8. Use ACF and the autoplot functions to plot the autocorrelation of the remainder. According to the Box-Jenkins methodology, can this model be improved?**

```{r}
autoplot(acf(ts_stl_cars))
```

Yes.

```{r}
stl_decomp %>% ACF(remainder) %>%  autoplot()
```

There is quite strong autocorrelation left, even some cyclic behaviour.

### 3.2 ARIMA modeling

**9. Create two ARIMA models for this data using the following syntax. Using the help files, explain the first ARIMA model in your own words. Then briefly explain how the second model came about.**

```{r}
models <- 
  ts_cars %>%
  model(
    ARIMA = ARIMA(value ~ pdq(1, 1, 1) + PDQ(0, 0, 0)),
    SARIMA = ARIMA(value)
  )

models
```

ARIMA has the AR and MA processes and it differentiates once, but it does not take into account seasonality. SARIMA is the same but it does take into account seasonality.

The first model is a non-seasonal ARIMA(1, 1, 1) model, meaning a single AR, first difference, and a single MA parameter.
The second model is a fully data-driven SARIMA model, chosen based on the AICc by the fable package.

**10. Create forecasts for these two models using the forecast() function. Use a horizon of 5 years. Plot these forecasts using the autoplot() function. Explain the main similarities and differences between the two forecasts.**

```{r}
(models$ARIMA %>%
  forecast(h = 5 * 4))[[1]] %>% 
  autoplot(ts_cars)

(models$SARIMA %>%
  forecast(h = 5 * 4))[[1]] %>% 
  autoplot(ts_cars)
```

Both the models have an increasing uncertainty with time. However, the SARIMA model has seasonality, while ARIMA only seems to take the average when looking at it.

Both models don't show a strong trend. The SARIMA model neatly shows the seasonality in the data, and the ARIMA does not. The confidence bands seem approximately equal ly wide and are appropriately increasing in size.

### 3.3 Comparing SARIMA and Prophet forecasting methods

**11. Fit a data-driven seasonal ARIMA and a prophet model for the ts_cars datasets between 1980 and 1995. Then, create forecasts until the year 2000, and compare the model forecasts to the observed data for this period. Which model works better in this setting?**

```{r}
train_ts_cars <-
  ts_cars %>% 
  filter(index > yearquarter("1980 Q1"), index < yearquarter("1995 Q4"))

SARIMA_train <-
  train_ts_cars %>% 
  model(ARIMA(value))

prophet_train <-
  train_ts_cars %>% 
  model(prophet(value))

SARIMA_train %>% 
  forecast(h = 4*5) %>% 
  autoplot(train_ts_cars) +
  autolayer(ts_cars %>% filter(index > yearquarter("1980 Q1"), , index < yearquarter("2000 Q4")))

prophet_train %>% 
  forecast(h = 4*5) %>% 
  autoplot(train_ts_cars) +
  autolayer(ts_cars %>% filter(index > yearquarter("1980 Q1"), , index < yearquarter("2000 Q4")))
```

The SARIMA model seems to be better, since the values are closer to the true values and for the prophet model the uncertainties do not even reach the true value.

Both models slightly underestimate the `value`. We could argue that the SARIMA model works better in this case because the confidence bands include the real data, whereas this is not the case for the prophet model. The prophet model is a bit "overconfident".